{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file vgg_cifar10_100_bottleneck_features_train.p\n",
      "Validation file vgg_cifar10_bottleneck_features_validation.p\n",
      "(1000, 1, 1, 512) (1000, 1)\n",
      "(10000, 1, 1, 512) (10000, 1)\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s - loss: 5.2074 - acc: 0.0810 - val_loss: 4.3127 - val_acc: 0.1046\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s - loss: 4.0272 - acc: 0.1390 - val_loss: 3.7145 - val_acc: 0.1583\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s - loss: 3.5171 - acc: 0.1840 - val_loss: 3.2960 - val_acc: 0.2082\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s - loss: 3.0469 - acc: 0.2410 - val_loss: 2.8634 - val_acc: 0.2559\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s - loss: 2.6013 - acc: 0.2980 - val_loss: 2.5151 - val_acc: 0.3069\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s - loss: 2.2491 - acc: 0.3460 - val_loss: 2.2490 - val_acc: 0.3428\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.9707 - acc: 0.3900 - val_loss: 2.0463 - val_acc: 0.3749\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.7546 - acc: 0.4370 - val_loss: 1.8762 - val_acc: 0.4135\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.5713 - acc: 0.4850 - val_loss: 1.7297 - val_acc: 0.4467\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.4062 - acc: 0.5470 - val_loss: 1.6171 - val_acc: 0.4737\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.2822 - acc: 0.5830 - val_loss: 1.5257 - val_acc: 0.5001\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.1730 - acc: 0.6180 - val_loss: 1.4417 - val_acc: 0.5241\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s - loss: 1.0824 - acc: 0.6430 - val_loss: 1.3705 - val_acc: 0.5470\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.9996 - acc: 0.6740 - val_loss: 1.3131 - val_acc: 0.5652\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.9352 - acc: 0.6940 - val_loss: 1.2659 - val_acc: 0.5798\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.8752 - acc: 0.7110 - val_loss: 1.2225 - val_acc: 0.5911\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.8227 - acc: 0.7300 - val_loss: 1.1876 - val_acc: 0.6028\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.7776 - acc: 0.7480 - val_loss: 1.1575 - val_acc: 0.6127\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.7365 - acc: 0.7580 - val_loss: 1.1298 - val_acc: 0.6215\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.7001 - acc: 0.7740 - val_loss: 1.1051 - val_acc: 0.6290\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6657 - acc: 0.7900 - val_loss: 1.0838 - val_acc: 0.6352\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6360 - acc: 0.7980 - val_loss: 1.0654 - val_acc: 0.6419\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.6088 - acc: 0.8010 - val_loss: 1.0484 - val_acc: 0.6473\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5836 - acc: 0.8160 - val_loss: 1.0336 - val_acc: 0.6528\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5592 - acc: 0.8210 - val_loss: 1.0194 - val_acc: 0.6597\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5358 - acc: 0.8340 - val_loss: 1.0079 - val_acc: 0.6632\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.5152 - acc: 0.8390 - val_loss: 0.9957 - val_acc: 0.6671\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4956 - acc: 0.8520 - val_loss: 0.9846 - val_acc: 0.6719\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4774 - acc: 0.8570 - val_loss: 0.9759 - val_acc: 0.6757\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4596 - acc: 0.8620 - val_loss: 0.9664 - val_acc: 0.6795\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4432 - acc: 0.8750 - val_loss: 0.9594 - val_acc: 0.6814\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4281 - acc: 0.8830 - val_loss: 0.9521 - val_acc: 0.6867\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.4132 - acc: 0.8910 - val_loss: 0.9452 - val_acc: 0.6888\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3998 - acc: 0.8960 - val_loss: 0.9385 - val_acc: 0.6897\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3863 - acc: 0.9030 - val_loss: 0.9329 - val_acc: 0.6910\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3737 - acc: 0.9030 - val_loss: 0.9269 - val_acc: 0.6952\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3617 - acc: 0.9080 - val_loss: 0.9222 - val_acc: 0.6967\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3499 - acc: 0.9150 - val_loss: 0.9173 - val_acc: 0.6990\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3393 - acc: 0.9190 - val_loss: 0.9138 - val_acc: 0.6996\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3287 - acc: 0.9230 - val_loss: 0.9088 - val_acc: 0.7033\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3192 - acc: 0.9280 - val_loss: 0.9057 - val_acc: 0.7063\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3105 - acc: 0.9280 - val_loss: 0.9009 - val_acc: 0.7073\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.3008 - acc: 0.9360 - val_loss: 0.8976 - val_acc: 0.7088\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2926 - acc: 0.9380 - val_loss: 0.8947 - val_acc: 0.7086\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2840 - acc: 0.9430 - val_loss: 0.8911 - val_acc: 0.7102\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2760 - acc: 0.9440 - val_loss: 0.8886 - val_acc: 0.7120\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2690 - acc: 0.9490 - val_loss: 0.8859 - val_acc: 0.7134\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2612 - acc: 0.9520 - val_loss: 0.8845 - val_acc: 0.7139\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2547 - acc: 0.9520 - val_loss: 0.8825 - val_acc: 0.7145\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s - loss: 0.2479 - acc: 0.9560 - val_loss: 0.8792 - val_acc: 0.7158\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ddigges/anaconda/envs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# command line flags\n",
    "flags.DEFINE_string('training_file', 'vgg_cifar10_100_bottleneck_features_train.p', \"Bottleneck features training file (.p)\")\n",
    "flags.DEFINE_string('validation_file', 'vgg_cifar10_bottleneck_features_validation.p', \"Bottleneck features validation file (.p)\")\n",
    "flags.DEFINE_integer('epochs', 50, \"The number of epochs.\")\n",
    "flags.DEFINE_integer('batch_size', 256, \"The batch size.\")\n",
    "\n",
    "\n",
    "def load_bottleneck_data(training_file, validation_file):\n",
    "    \"\"\"\n",
    "    Utility function to load bottleneck features.\n",
    "\n",
    "    Arguments:\n",
    "        training_file - String\n",
    "        validation_file - String\n",
    "    \"\"\"\n",
    "    print(\"Training file\", training_file)\n",
    "    print(\"Validation file\", validation_file)\n",
    "\n",
    "    with open(training_file, 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(validation_file, 'rb') as f:\n",
    "        validation_data = pickle.load(f)\n",
    "\n",
    "    X_train = train_data['features']\n",
    "    y_train = train_data['labels']\n",
    "    X_val = validation_data['features']\n",
    "    y_val = validation_data['labels']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    # load bottleneck data\n",
    "    X_train, y_train, X_val, y_val = load_bottleneck_data(FLAGS.training_file, FLAGS.validation_file)\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_val.shape, y_val.shape)\n",
    "\n",
    "    nb_classes = len(np.unique(y_train))\n",
    "\n",
    "    # define model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    inp = Input(shape=input_shape)\n",
    "    flattened_inp = Flatten()(inp)\n",
    "    output = Dense(nb_classes, activation='softmax')(flattened_inp)\n",
    "    model = Model(inp, output)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train model\n",
    "    model.fit(X_train, y_train, nb_epoch=FLAGS.epochs, batch_size=FLAGS.batch_size, validation_data=(X_val, y_val), shuffle=True)\n",
    "\n",
    "\n",
    "# parses flags and calls the `main` function above\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
